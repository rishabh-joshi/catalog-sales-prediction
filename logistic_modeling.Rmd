---
title: "Logistic Regression Models"
author: "Rush"
output:
  html_document:
    keep_md: TRUE
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(comment = "")
knitr::opts_chunk$set(fig.align = 'center')
knitr::opts_chunk$set(cache = TRUE)
```

In this file, we try multiple logistic regression models and compare them based on the values of AIC, classification accuracy, $F_1$ scores, etc.

## Data Preprocessing

Loading required libraries
```{r, warning=FALSE, message=FALSE}
library(dplyr)
library(lubridate)
library(ggplot2)
library(tidyr)
library(reshape2)
library(car)
library(bestglm)
library(caret)
library(glmnet)
library(pROC)
library(SDMTools)
```

Reading the data
```{r}
train <- read.csv("clean_train.csv", stringsAsFactors = FALSE)
test <- read.csv("clean_test.csv", stringsAsFactors = FALSE)
```


Converting both the date variabels to their corresponding integer values, which specifies the number of days since the date 1970-01-01. This is done to make the date continuous variable. Some other variables are converted to factors.

```{r}
train <- train %>%
    mutate(large_avg = factor(large_avg), pur3yr = factor(pur3yr)) %>%
    mutate(lpurseason = factor(lpurseason), slscmp = factor(slscmp)) %>%
    mutate(id = as.character(id))

test <- test %>%
    mutate(large_avg = factor(large_avg), pur3yr = factor(pur3yr)) %>%
    mutate(lpurseason = factor(lpurseason), slscmp = factor(slscmp)) %>%
    mutate(id = as.character(id))
```

Removing last purchase year from the data because we have already accounted for the last purchase date in the `datelp6` variable. Now we create a test and a training data set for the logistic regression modeling process.

```{r}
train_logistic <- select(train, -train, -targdol, -lpuryear, -lpurseason_year)
test_logistic <- select(test, -train, -targdol, -lpuryear, -lpurseason_year)

train_linear <- train %>%
    filter(responded==1) %>%
    select(-datead6, -datelp6) %>%
    select(-train, -lpuryear, -responded, -lpurseason_year, -recency_bin) 

test_linear <- test %>%
    select(-datead6, -datelp6) %>%
    select(-train, -lpuryear, -responded, -lpurseason_year, -recency_bin)
```



## Exploratory data analysis

### Scatter plots

Plotting the response variable with the preditor variables to see if we can find any pattern

```{r, eval=FALSE}
ggplot(data = train, aes(x = datead6, y = targdol)) +
    geom_point()

ggplot(data = train, aes(x = datelp6, y = targdol)) +
    geom_point()

ggplot(data = train, aes(x = slstyr, y = targdol)) +
    geom_point()

ggplot(data = train, aes(x = slslyr, y = targdol)) +
    geom_point()

ggplot(data = train, aes(x = sls2ago, y = targdol)) +
    geom_point()

ggplot(data = train, aes(x = sls3ago, y = targdol)) +
    geom_point()

ggplot(data = train, aes(x = log(slshist+1), y = targdol)) +
    geom_point()

ggplot(data = train, aes(x = log(ordtyr+1), y = targdol)) +
    geom_point()

ggplot(data = train, aes(x = ordlyr, y = targdol)) +
    geom_point()

ggplot(data = train, aes(x = ord2ago, y = targdol)) +
    geom_point()

ggplot(data = train, aes(x = ord3ago, y = targdol)) +
    geom_point()

ggplot(data = train, aes(x = ordhist, y = targdol)) +
    geom_point()

ggplot(data = train, aes(x = lpurseason, y = targdol)) +
    geom_point()

ggplot(data = train, aes(x = ordtyr, y = targdol)) +
    geom_point()
```

### Histograms

Checking univariate distributions of the variables.
```{r, eval=FALSE}
qplot(x = targdol, data = train_linear, geom = "histogram")
qplot(x = datead6, data = train_linear, geom = "histogram")
qplot(x = datelp6, data = train_linear, geom = "histogram")
qplot(x = slstyr-slslyr + min(slstyr-slslyr), data = train_linear, geom = "histogram")
qplot(x = slslyr-sls2ago, data = train_linear, geom = "histogram")
qplot(x = sls2ago-sls3ago, data = train_linear, geom = "histogram")
qplot(x = sls3ago-sls4bfr, data = train_linear, geom = "histogram")
qplot(x = slshist, data = train_linear, geom = "histogram")
qplot(x = ordtyr, data = train_linear, geom = "histogram")
qplot(x = ordlyr, data = train_linear, geom = "histogram")
qplot(x = ord2ago, data = train_linear, geom = "histogram")
qplot(x = ord3ago, data = train_linear, geom = "histogram")
qplot(x = ordhist, data = train_linear, geom = "histogram")

qplot(x = falord, data = train_linear, geom = "histogram")
qplot(x = sprord, data = train_linear, geom = "histogram")
qplot(x = recency_bin, data = train_linear, geom = "histogram")
qplot(x = recency, data = train_linear, geom = "histogram")
qplot(x = lifetime, data = train_linear, geom = "histogram")
qplot(x = active, data = train_linear, geom = "histogram")
qplot(x = avg_amount, data = train_linear, geom = "histogram")
qplot(x = ord4bfr, data = train_linear, geom = "histogram")
qplot(x = sls4bfr, data = train_linear, geom = "histogram")
```

We observe that many of these distributions are skewed. Therefore, we take the log transforamtion to see if these distributions become more symmetric.

### Histograms of log transformed predictors

Checking distributions after log transformation. Adding a small displacement to avoid taking log of zeros.

A small constant to add before taking log
```{r}
K = 0.0001
```


```{r, eval=FALSE}
qplot(x = log(targdol + K), data = train, geom = "histogram")
qplot(x = log(datead6 + K), data = train, geom = "histogram")
qplot(x = log(datelp6 + K), data = train, geom = "histogram")
qplot(x = log(slstyr + K), data = train, geom = "histogram")
qplot(x = log(slslyr + K), data = train, geom = "histogram")
qplot(x = log(sls2ago + K), data = train, geom = "histogram")
qplot(x = log(sls3ago + K), data = train, geom = "histogram")
qplot(x = log(slshist + K), data = train, geom = "histogram")
qplot(x = log(ordtyr + K), data = train, geom = "histogram")
qplot(x = log(ordlyr + K), data = train, geom = "histogram")
qplot(x = log(ord2ago + K), data = train, geom = "histogram")
qplot(x = log(ord3ago + K), data = train, geom = "histogram")
qplot(x = log(ordhist + K), data = train, geom = "histogram")
qplot(x = log(falord + K), data = train, geom = "histogram")
qplot(x = log(sprord + K), data = train, geom = "histogram")
qplot(x = log(recency_bin + K), data = train, geom = "histogram")
# qplot(x = log(recency + K), data = train, geom = "histogram")
# qplot(x = log(lifetime + K), data = train, geom = "histogram")
# qplot(x = log(active + K), data = train, geom = "histogram")
qplot(x = log(avg_amount + K), data = train, geom = "histogram")
# qplot(x = log(large_avg + K), data = train, geom = "histogram")
qplot(x = log(ord4bfr + K), data = train, geom = "histogram")
qplot(x = log(sls4bfr + K), data = train, geom = "histogram")
```

## Logistic regression models

### Fitting a basic logistic regression model

A logistic regression model with all the variabels to set a base line. Some variabels are removed from the model becuase they were introducing multicollinearity and hence resulting in NA values while fitting the model.

```{r}
logistic1 <- glm(responded ~ . - ordhist - slshist - recency_bin - ord4bfr, data = select(train_logistic, -id, -datead6, -datelp6), 
              family = binomial)
summary(logistic1)
```

Checking the Correct Classification Rate (CCR) or the accuracy on the test data.

```{r, echo=FALSE}
pred <- fitted(logistic1)

pred_test <- predict(logistic1, newdata = select(test_logistic, -id), 
                     type = 'response')
acc <- 0
thresh <- 0
for (i in seq(0,1,0.01)){
    tab <- table(test_logistic$responded, pred_test>i)
    CCR <- sum(diag(tab))/sum(tab)
    if(CCR > acc){
        acc <- CCR
        thresh <- i
        cat(paste(thresh, acc, " "), "\n")
    }
}

thresh
caret::confusionMatrix(train_logistic$responded, as.integer(pred>thresh))
```

Checking the CCR on the test data
```{r}
caret::confusionMatrix(test_logistic$responded, as.integer(pred_test>thresh))
```

**CCR in the test data = 0.9152**

Checking the F1 score of this logistic model
```{r}
F_meas(factor(as.integer(pred_test>thresh)), 
       reference = as.factor(test_logistic$responded), relevant = "1")
```

**F1 score = 0.325**

### Fitting a logistic model with log transformed predictors

```{r}
logistic2 <- glm(responded ~ log(slstyr + K) + log(slslyr + K) +
                log(sls2ago + K) + log(sls3ago + K) + log(sls4bfr + K) +
                log(ordtyr + K) + log(ordlyr + K) +
                log(ord2ago + K) + log(ord3ago + K) + log(ord4bfr + K) +
                log(sprord+K) + log(falord+K) +
                log(avg_amount + K) + large_avg + active + lifetime + 
                recency + lpurseason, data = select(train_logistic, -id), 
        family = binomial)
summary(logistic2)
```

Checking the CCR on the test data
```{r, echo=FALSE}
pred <- fitted(logistic2)

pred_test <- predict(logistic2, newdata = select(test_logistic, -id), 
                     type = 'response')
acc <- 0
thresh <- 0
for (i in seq(0,1,0.01)){
    tab <- table(test_logistic$responded, pred_test>i)
    CCR <- sum(diag(tab))/sum(tab)
    if(CCR > acc){
        acc <- CCR
        thresh <- i
        cat(paste(thresh, acc, " "), "\n")
    }
}

thresh
caret::confusionMatrix(train_logistic$responded, as.integer(pred>thresh))
```

Checking the CCR on the test data
```{r}
caret::confusionMatrix(test_logistic$responded, as.integer(pred_test>thresh))
```

**CCR on the test data = 0.9242**

Checking the F1 score of this logistic model
```{r}
F_meas(factor(as.integer(pred_test>thresh)), 
       reference = as.factor(test_logistic$responded), relevant = "1")
```

**F1 score on the test data = 0.39**

Significant improvement from the previous model. We definitely should regress on the log of predictors.

### Adding interactions between sales

We add some interactions between sales of last 1, 2 and 3 years to capture consistency. We added these interactions one by one to see if they increase the CCR and the F1 Score on the test set. We kept all the interactions that resulted in an increase in the CCR and F1 Score. Adding similar kinds of interactions between the orders of last 1,2 or 3 years did not increase the F1 score or the CCR. Therefore, we did not add them.

```{r}
logistic3 <- glm(responded ~ log(slstyr + K) + log(slslyr + K) +
                log(sls2ago + K) + log(sls3ago + K) + log(sls4bfr + K) +
                log(ordtyr + K) + log(ordlyr + K) +
                log(ord2ago + K) + log(ord3ago + K) + log(ord4bfr + K) +
                log(sprord+K) + log(falord+K) +
                log(avg_amount + K) + large_avg + active + lifetime + 
                recency + lpurseason + 
                log(slstyr + K):log(slslyr + K) +
                log(slslyr + K):log(sls2ago + K) + 
                log(sls2ago + K):log(sls3ago + K) +
                log(sls3ago + K):log(sls4bfr + K), 
                data = select(train_logistic, -id), 
        family = binomial)
summary(logistic3)
```

Checking the CCR on the test data
```{r, echo=FALSE}
pred <- fitted(logistic3)
pred_test <- predict(logistic3, newdata = select(test_logistic, -id), 
                     type = 'response')
acc <- 0
thresh <- 0
for (i in seq(0,1,0.01)){
    tab <- table(test_logistic$responded, pred_test>i)
    CCR <- sum(diag(tab))/sum(tab)
    if(CCR > acc){
        acc <- CCR
        thresh <- i
        cat(paste(thresh, acc, " "), "\n")
    }
}

thresh
caret::confusionMatrix(train_logistic$responded, as.integer(pred>thresh))
```

Checking the CCR on the test data
```{r}
caret::confusionMatrix(test_logistic$responded, as.integer(pred_test>thresh))
```

**CCR on the test data = 0.9276**

Checking the F1 score of this logistic model
```{r}
F_meas(factor(as.integer(pred_test>thresh)), 
       reference = as.factor(test_logistic$responded), relevant = "1")
```

**F1 score on the test data = 0.4479**

Significant improvement from the previous model. Therefore we should keep these interactions in the losgistic model.

### Adding some more interactions

```{r}
logistic4 <- glm(responded ~ log(slstyr + K) + log(slslyr + K) +
                log(sls2ago + K) + log(sls3ago + K) + log(sls4bfr + K) +
                log(ordtyr + K) + log(ordlyr + K) +
                log(ord2ago + K) + log(ord3ago + K) + log(ord4bfr + K) +
                log(sprord+K) + log(falord+K) +
                log(avg_amount + K) + large_avg + active + lifetime + 
                recency + lpurseason + 
                log(slstyr + K):log(slslyr + K) +
                log(slslyr + K):log(sls2ago + K) + 
                log(sls2ago + K):log(sls3ago + K) +
                log(sls3ago + K):log(sls4bfr + K) +
            
                recency:active + lifetime:slscmp + 
                log(slstyr + K):log(ordtyr+ K) + 
                log(slstyr + K):recency, 
                data = select(train_logistic, -id), 
        family = binomial)
summary(logistic4)
```

Checking the CCR on the train data
```{r, echo=FALSE}
pred <- fitted(logistic4)
pred_test <- predict(logistic4, newdata = select(test_logistic, -id), 
                     type = 'response')
acc <- 0
thresh <- 0
for (i in seq(0,1,0.01)){
    tab <- table(test_logistic$responded, pred_test>i)
    CCR <- sum(diag(tab))/sum(tab)
    if(CCR > acc){
        acc <- CCR
        thresh <- i
        cat(paste(thresh, acc, " "), "\n")
    }
}

thresh
caret::confusionMatrix(train_logistic$responded, as.integer(pred>thresh))
```

Checking the CCR on the test data
```{r}
caret::confusionMatrix(test_logistic$responded, as.integer(pred_test>thresh))
```

**CCR on the test data = 0.9283**

Checking the F1 score of this logistic model
```{r}
F_meas(factor(as.integer(pred_test>thresh)), 
       reference = as.factor(test_logistic$responded), relevant = "1")
```

**F1 score on the test data = 0.4562**

Significant improvement from the previous model. Therefore we should keep these interactions in the losgistic model.


### Adding some more interactions

Adding these interactions increased the CCR but resulted in a decrease in the F1 score.

```{r}
logistic5 <- glm(responded ~ log(slstyr + K) + log(slslyr + K) +
                log(sls2ago + K) + log(sls3ago + K) + log(sls4bfr + K) +
                log(ordtyr + K) + log(ordlyr + K) +
                log(ord2ago + K) + log(ord3ago + K) + log(ord4bfr + K) +
                log(sprord+K) + log(falord+K) +
                log(avg_amount + K) + large_avg + active + lifetime + 
                recency + lpurseason + 
                log(slstyr + K):log(slslyr + K) +
                log(slslyr + K):log(sls2ago + K) + 
                log(sls2ago + K):log(sls3ago + K) +
                log(sls3ago + K):log(sls4bfr + K) +
            
                recency:active + lifetime:slscmp + 
                log(slstyr + K):log(ordtyr+ K) + 
                log(slstyr + K):recency + 
                    
                    log(slslyr + K):recency +
                    log(sls2ago + K):log(ord2ago + K) + 
                    log(avg_amount + K):recency, 
                data = select(train_logistic, -id), 
        family = binomial)
summary(logistic5)
```

Checking the CCR on the train data
```{r, echo=FALSE}
pred <- fitted(logistic5)
pred_test <- predict(logistic5, newdata = select(test_logistic, -id), 
                     type = 'response')
acc <- 0
thresh <- 0
for (i in seq(0,1,0.01)){
    tab <- table(test_logistic$responded, pred_test>i)
    CCR <- sum(diag(tab))/sum(tab)
    if(CCR > acc){
        acc <- CCR
        thresh <- i
        cat(paste(thresh, acc, " "), "\n")
    }
}

thresh
caret::confusionMatrix(train_logistic$responded, as.integer(pred>thresh))
```

Checking the CCR on the test data
```{r}
caret::confusionMatrix(test_logistic$responded, as.integer(pred_test>thresh))
```

**CCR on the test data = 0.9289**

Checking the F1 score of this logistic model
```{r}
F_meas(factor(as.integer(pred_test>thresh)), 
       reference = as.factor(test_logistic$responded), relevant = "1")
```

**F1 score on the test data = 0.4443**

### Backwards stepwise on logistic5 

```{r, echo=FALSE}
bwd_log <- step(logistic5, direction = "both")
summary(bwd_log)

pred <- fitted(bwd_log)
pred_test <- predict(bwd_log, newdata = select(test_logistic, -id), 
                     type = 'response')
acc <- 0
thresh <- 0
for (i in seq(0,1,0.01)){
    tab <- table(test_logistic$responded, pred_test>i)
    CCR <- sum(diag(tab))/sum(tab)
    if(CCR > acc){
        acc <- CCR
        thresh <- i
        cat(paste(thresh, acc, " "), "\n")
    }
}

thresh
caret::confusionMatrix(test_logistic$responded, as.integer(pred_test>thresh))
F_meas(factor(as.integer(pred_test>thresh)), 
       reference = as.factor(test_logistic$responded), relevant = "1")

```


### Summary of all the logistic regression models

The CCR/accuracies and F1 scores of all the logistic regression models are given below:

- logistic1: CCR = 0.9152, F1 Score = 0.325 AIC = 25934
- logistic2: CCR = 0.9242, F1 Score = 0.39 AIC = 24332
- logistic3: CCR = 0.9276, F1 Score = 0.4479, AIC = 24080 
- logistic4: CCR = 0.9283, F1 Score = 0.4613, AIC = 23992
- logistic5: CCR = 0.9289, F1 Score = 0.4443, AIC = 23873
- (stepwise on logistic5) bwd_log: CCR = 0.929, F1 Score = 0.4439, AIC = 23870 

3 predictors removed from logistic5 after doing stepwise regression


### Writing the predicted probabilites to a file

```{r}
prob_test <- data.frame(id = test_logistic$id, prob = pred_test)
write.csv(prob_test, "probabilities.csv", row.names=FALSE)
```

